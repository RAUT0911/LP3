1)
# imports
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib as mpl
import random as rd

2)
df=pd.read_csv("uber.csv")

3)
df

4)
df.hist()

5)
df.corr

6)
df.types

7)
df1 = df
df1.describe()

8)
df1.columns

9)
df1.fare_amount

10)
df1.fare_amount.describe()

11)
corr=df1.corr
corr

12)(Identify outliers)
print(df1.columns)


13)
print(df1.head())

14)
df1.columns = df1.columns.str.strip()

15)
import pandas as pd
import numpy as np

# Example of using IQR to detect outliers
Q1 = df1['fare_amount'].quantile(0.25)
Q3 = df1['fare_amount'].quantile(0.75)
IQR = Q3 - Q1
outliers = df1[(df1['fare_amount'] < (Q1 - 1.5 * IQR)) | (df1['fare_amount'] > (Q3 + 1.5 * IQR))]


16)
print(df1.dtypes)

17) (Check the correlation)
df1['pickup_datetime'] = pd.to_datetime(df1['pickup_datetime'])

18)
numeric_df = df1.select_dtypes(include=[np.number])
corr_matrix = numeric_df.corr()


19)
sns.heatmap(corr_matrix, annot=True, fmt=".2f")


20) (Implement Linear Regression)
print(df1.isna().sum())

21)
df1 = df1.dropna()

22) 
print(df1.dtypes)

23)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

24)
# Define input features and target variable
x = df1[['passenger_count']]
y = df1['fare_amount']

# Initialize the scaler
scaler = MinMaxScaler()

# Scale the entire feature dataset
x_scaled = scaler.fit_transform(x)

# Split the scaled data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25, random_state=20)


25)
print(x_scaled.shape)
print(x_train.shape)
print(x_test.shape)

26)
from sklearn.linear_model import LinearRegression

# Instantiate LinearRegression Model
lr = LinearRegression()

# Fit method to train model 
lr.fit(x_train, y_train)


27)
print(lr.predict(x_test))
print(lr.score(x_train, y_train))
print(lr.coef_)
print(lr.intercept_)

28)
y_pred = lr.predict(x_test)
y_pred

29)
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, adjusted_rand_score

# Evaluate the model
print("Scikit-Learn Model Evaluation:")
print(f"R-squared: {r2_score(y_test, y_pred):.4f}") # r2 value represents accuracy. 
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.4f}")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")


30)
# Import
from sklearn.ensemble import RandomForestRegressor

# Instantiation
rfr = RandomForestRegressor() 

# Fit RandomForest Model
rfr.fit(x_test, y_test)

31)
# Prediction on RandomForest Model x_test -> y_test
y_pred = rfr.predict(x_test)
y_pred

32)
# Evaluation of Model(Evaluation Matrices)
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, adjusted_rand_score

# Evaluate the model
print("Scikit-Learn Model Evaluation:")
print(f"R-squared: {r2_score(y_test, y_pred):.4f}") # r2 value represents accuracy. 
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.4f}")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")

33)
'''

# Cross-validation
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
print(f"Cross-Validated MSE: {-cv_scores.mean():.2f}")

# Fit the model using statsmodels
X_train_sm = sm.add_constant(X_train)  # Add constant term for intercept
model_sm = sm.OLS(y_train, X_train_sm).fit()

# Summary of the statsmodels results
print("\nStatsmodels Regression Summary:")
print(model_sm.summary())





